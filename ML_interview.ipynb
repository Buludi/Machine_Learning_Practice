{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML interview.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0YUp7iDbRQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYvZYc0BjP6K",
        "colab_type": "text"
      },
      "source": [
        "## MissingDate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm2861iYcCU8",
        "colab_type": "text"
      },
      "source": [
        "select data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYSDO451bvFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numerical feature\n",
        "num_cols = loan_data.select_dtypes(include=['number'])\n",
        "num_cols = loan_data.select_dtypes(include=[np.number])\n",
        "# categorical deature\n",
        "cat_cols = loan_data.select_dtypes(include=['category'])\n",
        "\n",
        "cat_cols = loan_data.select_dtypes(include=[object])\n",
        "# datetime deature\n",
        "datetime_cols = loan_data.select_dtypes(include=['datetime'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ngz3DUWc7Gd",
        "colab_type": "text"
      },
      "source": [
        "imputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HB7ARFW9gKAZ",
        "colab": {}
      },
      "source": [
        "# Import imputer module\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Subset numeric features: numeric_cols\n",
        "numeric_cols = loan_data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Impute with mean\n",
        "imp_mean = SimpleImputer(strategy='mean')\n",
        "loans_imp_mean = imp_mean.fit_transform(numeric_cols)\n",
        "\n",
        "# Convert returned array to DataFrame\n",
        "loans_imp_meanDF = pd.DataFrame(loans_imp_mean, columns=numeric_cols.columns)\n",
        "\n",
        "# Check for missing values\n",
        "print(loans_imp_meanDF.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lFbXY6sgLhT",
        "colab_type": "text"
      },
      "source": [
        "Iterative imputation (sklearn [document](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html) )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8zGoB5agMTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Subset numeric features: numeric_cols\n",
        "numeric_cols = loan_data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Iteratively impute\n",
        "imp_iter = IterativeImputer(max_iter =5, sample_posterior=True, random_state=123)\n",
        "loans_imp_iter = imp_iter.fit_transform(numeric_cols )\n",
        "\n",
        "# Convert returned array to DataFrame\n",
        "loans_imp_iterDF = pd.DataFrame(loans_imp_iter, columns=numeric_cols.columns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BHyFYLYiWWM",
        "colab_type": "text"
      },
      "source": [
        "## Data distributions and transformations\n",
        "- train test split\n",
        "  - avoid train and test data set has different distribution \n",
        "- Log transform can normalize a feature which demonstrates a non-Gaussian distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_WgpgWMjTxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create `loan_data` subset: loan_data_subset\n",
        "loan_data_subset = loan_data[['Credit Score','Annual Income','Loan Status']]\n",
        "\n",
        "# Create train and test sets\n",
        "trainingSet, testSet = train_test_split(loan_data_subset, test_size=0.2, random_state=123)\n",
        "\n",
        "# Examine pairplots (trainingSet and testSet have different distributions)\n",
        "plt.figure()\n",
        "sns.pairplot(trainingSet, hue='Loan Status', palette='RdBu')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "sns.pairplot(testSet, hue='Loan Status', palette='RdBu')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqthXgWFmqIh",
        "colab_type": "text"
      },
      "source": [
        "xxx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FX42S66nWCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subset loan_data\n",
        "cr_yrs = loan_data['Years of Credit History']\n",
        "\n",
        "# Histogram and kernel density estimate\n",
        "plt.figure()\n",
        "#sns.kdeplot(cr_yrs)\n",
        "sns.distplot(cr_yrs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juWjT6GCoLj7",
        "colab_type": "code",
        "outputId": "34f98655-0307-4356-d0d0-e7c473e94800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "## In this notebook I talk about scaling and normalizing data. \n",
        "## This minimal example shows how to use a Box Cox transformation to normalize both trianing and testing data. :)\n",
        "  \n",
        "# import modules\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# plotting modules\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# generate non-normal data\n",
        "original_data = np.random.exponential(size = 1000)\n",
        "\n",
        "# split into testing & training data\n",
        "train,test = train_test_split(original_data, shuffle=False)\n",
        "\n",
        "# transform training data & save lambda value\n",
        "train_data,fitted_lambda = stats.boxcox(train)\n",
        "\n",
        "# use lambda value to transform test data\n",
        "test_data = stats.boxcox(test, fitted_lambda)\n",
        "\n",
        "print('lambda=',fitted_lambda)\n",
        "# (optional) plot train & test\n",
        "fig, ax=plt.subplots(1,2)\n",
        "sns.distplot(train, ax=ax[0])\n",
        "sns.distplot(test, ax=ax[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda= 0.26634987332648186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f21504fb780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x/JJI/cBf6X/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMRQ9Wksoygv",
        "colab_type": "code",
        "outputId": "775aaf99-93e4-428b-c858-91c63a88aec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "fig, ax=plt.subplots(1,2)\n",
        "sns.distplot(train_data, ax=ax[0])\n",
        "sns.distplot(test_data, ax=ax[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2150e56ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qStLApeaoiyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subset loan_data\n",
        "cr_yrs = loan_data['Years of Credit History']\n",
        "\n",
        "# Box-Cox transformation\n",
        "cr_yrs_log = stats.boxcox(cr_yrs, lmbda=0)\n",
        "\n",
        "# Histogram and kernel density estimate\n",
        "plt.figure()\n",
        "sns.distplot(cr_yrs_log)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsfyFlKiznOA",
        "colab_type": "text"
      },
      "source": [
        "### Outlier\n",
        "- Detect outliers is by visualizing them graphically\n",
        "  - use sns.boxplot to visualizing outliers \n",
        "  - IQR\n",
        "  - 3Q +/- 1.5 IQR --> outliner\n",
        "  - Another convenient way for handling outliers is by calculating the Z-score which gives a threshold for outliers approximately +/-3 standard deviations away from the mean.\n",
        "  - calculating the Z-score using the scipy.stats module, omitting as well as replacing outliers using the mstats module from scipy.stats.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5P93YF24Mrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.stats \n",
        "\n",
        "# Print: before dropping\n",
        "print(numeric_cols.mean())\n",
        "print(numeric_cols.median())\n",
        "print(numeric_cols.max())\n",
        "\n",
        "# Create index of rows to keep\n",
        "idx = (np.abs(stats.zscore(numeric_cols)) < 3).all(axis=1)  # filter zscore <3 in numerical features\n",
        "\n",
        "# Concatenate numeric and categoric subsets\n",
        "ld_out_drop = pd.concat([numeric_cols.loc[idx], categoric_cols.loc[idx]], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM0lqvts8NsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Winsorize Monthly Debt with 5% upper and lower limits and print the mean, median and max before and after.\n",
        "\n",
        "# Print: before winsorize\n",
        "print((loan_data['Monthly Debt']).mean())\n",
        "print((loan_data['Monthly Debt']).median())\n",
        "print((loan_data['Monthly Debt']).max())\n",
        "\n",
        "# Winsorize numeric columns\n",
        "debt_win = mstats.winsorize(loan_data['Monthly Debt'], limits=[0.05, 0.05])\n",
        "\n",
        "# Convert to DataFrame, reassign column name\n",
        "debt_out = pd.DataFrame(debt_win, columns=['Monthly Debt'])\n",
        "\n",
        "# Print: after winsorize\n",
        "print(debt_out.mean())\n",
        "print(debt_out.median())\n",
        "print(debt_out.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIxsZ_h-9Lms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Find the median of the values of Monthly Debt that are lower than 2120 and replace outliers with it\n",
        "# Print: before replace with median\n",
        "print((loan_data['Monthly Debt']).mean())\n",
        "print((loan_data['Monthly Debt']).median())\n",
        "print((loan_data['Monthly Debt']).max())\n",
        "\n",
        "# Find median\n",
        "median = loan_data.loc[loan_data['Monthly Debt'] < 2120, 'Monthly Debt'].median()\n",
        "loan_data['Monthly Debt'] = np.where(loan_data['Monthly Debt'] > 2120, median, loan_data['Monthly Debt'])\n",
        "\n",
        "print((loan_data['Monthly Debt']).mean())\n",
        "print((loan_data['Monthly Debt']).median())\n",
        "print((loan_data['Monthly Debt']).max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDSbCdXD4BKK",
        "colab_type": "text"
      },
      "source": [
        "- standardization\n",
        "(Z score)\n",
        "- normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQmrZKZO4O3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Z-score standardization\n",
        "# Subset features\n",
        "numeric_cols = loan_data.select_dtypes(include=[np.number])\n",
        "categoric_cols = loan_data.select_dtypes(include=[object])\n",
        "\n",
        "# Instantiate\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform, convert to DF\n",
        "numeric_cols_scaled = scaler.fit_transform(numeric_cols)\n",
        "numeric_cols_scaledDF = pd.DataFrame(numeric_cols_scaled, columns=numeric_cols.columns)\n",
        "\n",
        "# Concatenate categoric columns to scaled numeric columns\n",
        "final_DF = pd.concat([numeric_cols_scaledDF, categoric_cols], axis=1)\n",
        "print(final_DF.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaaahUdBB4o3",
        "colab_type": "text"
      },
      "source": [
        "### Regression: feature selection\n",
        "\n",
        "Feature selection methods\n",
        "- Filter: Rank features based on statistical performance\n",
        "- Wrapper: Use an ML method to evaluate performance\n",
        "- Embedded: Iterative modeltraining to extract features\n",
        "- Feature importance:tree-based ML models\n",
        "\n",
        "\n",
        "1) Filter method: correlation\n",
        "- Create correlation matrix with diabetes and a heatmap, then subset the features which have greater than 50% correlation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55oWa4_xJ2xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create correlation matrix and print it\n",
        "cor = diabetes.corr()\n",
        "print(cor)\n",
        "\n",
        "# Correlation matrix heatmap\n",
        "plt.figure()\n",
        "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
        "plt.show()\n",
        "\n",
        "#Correlation with output variable\n",
        "cor_target = abs(cor[\"progression\"])\n",
        "\n",
        "#Selecting highly correlated features\n",
        "best_features = cor_target[cor_target> 0.5]\n",
        "print(best_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vweoBIxhRb6q",
        "colab_type": "text"
      },
      "source": [
        "2) wrapper methods: feature selection using RFECV\n",
        "- Instantiate a linear kernel SVR estimator and a feature selector with 5 cross-validations, fit to features and target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvhwZFsWRbH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "# Instantiate estimator and feature selector\n",
        "svr_mod = SVR(kernel=\"linear\")\n",
        "feat_selector = RFECV(svr_mod, cv=5)\n",
        "\n",
        "# Fit\n",
        "feat_selector = feat_selector.fit(X, y)\n",
        "\n",
        "# Print support and ranking\n",
        "print(feat_selector.support_)\n",
        "print(feat_selector.ranking_)\n",
        "print(X.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1_Asw8mR538",
        "colab_type": "text"
      },
      "source": [
        "3) Lasso \n",
        "- Drop the unimportant column found in step 2 from X and instantiate a LarsCV object and fit it to your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOKvDcqdSUar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.linear_model import LarsCV\n",
        "\n",
        "# Drop feature suggested not important in step 2\n",
        "X = diabetes.drop('sex', axis=1)\n",
        "\n",
        "# Instantiate\n",
        "lars_mod = LarsCV(cv=5, normalize=False)\n",
        "\n",
        "# Fit\n",
        "feat_selector = lars_mod.fit(X, y)\n",
        "\n",
        "# Print r-squared score and estimated alpha\n",
        "print(lars_mod.score(X, y))\n",
        "print(lars_mod.alpha_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhIvVdPRSl8r",
        "colab_type": "text"
      },
      "source": [
        "4) tree based method (better method!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR5DHCTqTeit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate\n",
        "rf_mod = RandomForestRegressor(max_depth=2, random_state=123, \n",
        "              n_estimators=100, oob_score=True)\n",
        "\n",
        "# Fit\n",
        "rf_mod.fit(X, y)\n",
        "\n",
        "# Print\n",
        "print(diabetes.columns)\n",
        "print(rf_mod.feature_importances_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZel6wb-Uj4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "# Instantiate\n",
        "xt_mod = ExtraTreesRegressor()\n",
        "\n",
        "# Fit\n",
        "xt_mod.fit(X,y)\n",
        "\n",
        "# Print\n",
        "print(diabetes.columns)\n",
        "print(xt_mod.feature_importances_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxTzvaoCUlUA",
        "colab_type": "text"
      },
      "source": [
        "### Regularization\n",
        "- Lasso (L1)\n",
        "- Ridge (L2)\n",
        "- ElasticNet(L1+L2)\n",
        "\n",
        "-- Lasso uses the l-1 norm corresponding to the penalty parameter and the absolute value of the coefficients. Ridge regression performs l2 regularization, also known as l2-norm, which adds a penalty term to ordinary least squares using the penalty parameter and the sum of the squared coefficients.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP22o37sXGVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Lasso\n",
        "# Import modules\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.3)\n",
        "\n",
        "# Instantiate cross-validated lasso, fit\n",
        "lasso_cv = LassoCV(alphas=None, cv=10, max_iter=10000)\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "# Instantiate lasso, fit, predict and print MSE\n",
        "lasso = Lasso(alpha = lasso_cv.alpha_)\n",
        "lasso.fit(X_train, y_train)\n",
        "print(mean_squared_error(y_true= y_test, y_pred=lasso.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWzGJ4WVkPaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Ridge regularization\n",
        "# Import modules\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.3)\n",
        "\n",
        "# Instantiate cross-validated ridge, fit\n",
        "ridge_cv = RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "\n",
        "# Instantiate ridge, fit, predict and print MSE\n",
        "ridge = Ridge(alpha = ridge_cv.alpha_)\n",
        "ridge.fit(X_train, y_train)\n",
        "print(mean_squared_error(y_true=y_test, y_pred=ridge.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj4F21qX04uZ",
        "colab_type": "text"
      },
      "source": [
        "### Feature engineering: Classifcation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hIJBw0U09B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create X matrix and y array\n",
        "X = loan_data.drop('Loan Status', axis=1)\n",
        "y = loan_data['Loan Status']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Instantiate\n",
        "logistic = LogisticRegression()\n",
        "\n",
        "# Fit\n",
        "logistic.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "print(accuracy_score(y_true=y_test, y_pred=logistic.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSpxVzb66KIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dti_ratio variable\n",
        "monthly_income = loan_data[\"Annual Income\"]/12\n",
        "loan_data[\"dti_ratio\"] = loan_data[\"Monthly Debt\"]/monthly_income * 100\n",
        "loan_data = loan_data.drop([\"Monthly Debt\",\"Annual Income\"], axis=1)\n",
        "\n",
        "# Replace target variable levels\n",
        "loan_data[\"Loan Status\"] = loan_data[\"Loan Status\"].replace({'Fully Paid': 0, \n",
        "                                            'Charged Off': 1})\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "loan_data = pd.get_dummies(data=loan_data)\n",
        "\n",
        "# Print\n",
        "print(loan_data.head())\n",
        "\n",
        "# Create X matrix and y array\n",
        "X = loans_dti.drop(\"Loan Status\", axis=1)\n",
        "y = loans_dti[\"Loan Status\"]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
        "\n",
        "# Instantiate\n",
        "logistic_dti = LogisticRegression()\n",
        "\n",
        "# Fit\n",
        "logistic_dti.fit(X_train, y_train)\n",
        "\n",
        "# Predict and print accuracy\n",
        "print(accuracy_score(y_true=y_test, y_pred=logistic_dti.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpqfEEAC6_MA",
        "colab_type": "text"
      },
      "source": [
        "### Ensemble methods\n",
        "\n",
        "- bagging (bootstrap aggregation) - decrease variance (overfit)\n",
        "- boosting - decrease bias (underfit)\n",
        "- stacking\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O6tdPtf7ADN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### bagging\n",
        "\n",
        "# Instantiate bootstrap aggregation model\n",
        "bagged_model = BaggingClassifier(n_estimators=50, random_state=123)  # use decision tree by default\n",
        "\n",
        "# Fit\n",
        "bagged_fit = bagged_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "bagged_pred = bagged_model.predict(X_test)\n",
        "\n",
        "# Print accuracy score\n",
        "print(accuracy_score(y_test, bagged_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKJfg8WE_PGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### boostering\n",
        "\n",
        "# Boosting model\n",
        "boosted_model = AdaBoostClassifier(n_estimators=50, random_state=123)\n",
        "\n",
        "# Fit\n",
        "boosted_fit = boosted_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "boosted_pred = boosted_model.predict(X_test)\n",
        "\n",
        "# Print model accuracy\n",
        "print(accuracy_score(y_test, boosted_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosOINqP_21V",
        "colab_type": "text"
      },
      "source": [
        "### Dimensionality reduction: feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQTs8896_SM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### PCA\n",
        "# Import module\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Feature matrix and target array\n",
        "X = diabetes.drop('progression', axis=1)\n",
        "y = diabetes['progression']\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=3)\n",
        "\n",
        "# Fit and transform\n",
        "principalComponents = pca.fit_transform(X)\n",
        "\n",
        "# Print ratio of variance explained\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uniku2y2CV0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import module\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Feature matrix and target array\n",
        "X = diabetes.drop('progression', axis=1)\n",
        "y = diabetes['progression']\n",
        "\n",
        "# PCA\n",
        "svd = TruncatedSVD(n_components=3)\n",
        "\n",
        "# Fit and transform\n",
        "principalComponents = svd.fit_transform(X)\n",
        "\n",
        "# Print ratio of variance explained\n",
        "print(svd.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMqO69plG0PB",
        "colab_type": "text"
      },
      "source": [
        "visulization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km8zFbw3G2tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t-sne with loan data\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "loans = pd.read_csv('loans_dataset.csv')\n",
        "# Feature matrix\n",
        "X = loans.drop('Loan Status', axis=1)\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40)\n",
        "tsne_results = tsne.fit_transform(X)\n",
        "loans['t-SNE-PC-one'] = tsne_results[:,0]\n",
        "loans['t-SNE-PC-two'] = tsne_results[:,1]\n",
        "\n",
        "# t-sne viz\n",
        "plt.figure(figsize=(16,10))\n",
        "sns.scatterplot(\n",
        "x=\"t-SNE-PC-one\", y=\"t-SNE-PC-two\",\n",
        "hue=\"Loan Status\",\n",
        "palette=sns.color_palette([\"grey\",\"blue\"]),\n",
        "data=loans,\n",
        "legend=\"full\",\n",
        "alpha=0.3\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ba5MIkbJ_NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets = [0, 1]\n",
        "colors = ['r', 'b']\n",
        "\n",
        "# For loop to create plot\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = loan_data_PCA['Loan Status'] == target\n",
        "    ax.scatter(loan_data_PCA.loc[indicesToKeep, 'principal component 1']\n",
        "               , loan_data_PCA.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "\n",
        "# Legend    \n",
        "ax.legend(targets)\n",
        "ax.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPnIc9WjKc7z",
        "colab_type": "text"
      },
      "source": [
        "How to find the best PCA components? \n",
        "\n",
        "- use cumulative variance to determine the percentage of explained variance ratio for PCA components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFcGRgy_KgWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove target variable\n",
        "X = loan_data.drop('Loan Status', axis=1)\n",
        "\n",
        "# Instantiate\n",
        "pca = PCA(n_components=10)\n",
        "\n",
        "# Fit and transform\n",
        "principalComponents = pca.fit_transform(X)\n",
        "\n",
        "# List principal components names\n",
        "principal_components = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10']\n",
        "\n",
        "# Create a DataFrame\n",
        "pca_df = pd.DataFrame({'Variance Explained': pca.explained_variance_ratio_,\n",
        "             'PC':principal_components})\n",
        "\n",
        "# Plot DataFrame (scree plot)\n",
        "sns.barplot(x='PC',y='Variance Explained', \n",
        "           data=pca_df, color=\"c\")\n",
        "plt.show()\n",
        "\n",
        "# Instantiate, fit and transform\n",
        "pca2 = PCA()\n",
        "principalComponents2 = pca2.fit_transform(X)\n",
        "\n",
        "# Assign variance explained\n",
        "var = pca2.explained_variance_ratio_\n",
        "\n",
        "# Plot cumulative variance\n",
        "cumulative_var = np.cumsum(var)*100\n",
        "plt.plot(cumulative_var,'k-o',markerfacecolor='None',markeredgecolor='k')\n",
        "plt.title('Principal Component Analysis',fontsize=12)\n",
        "plt.xlabel(\"Principal Component\",fontsize=12)\n",
        "plt.ylabel(\"Cumulative Proportion of Variance Explained\",fontsize=12)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZFSfyeJNXNu",
        "colab_type": "text"
      },
      "source": [
        "### Clustering analysis: selecting the right clustering algorithm\n",
        "\n",
        "\n",
        "K-means clustering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wra1Dc79NazS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import module\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Create feature matrix\n",
        "X = diabetes.drop(\"progression\", axis=1)\n",
        "\n",
        "# Instantiate\n",
        "kmeans = KMeans(n_clusters=20, random_state=123)\n",
        "\n",
        "# Fit\n",
        "fit = kmeans.fit(X)\n",
        "\n",
        "# Print inertia\n",
        "print(\"Sum of squared distances for 20 clusters is\", kmeans.inertia_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Y6vCA15lTh",
        "colab_type": "text"
      },
      "source": [
        "Hierarchical agglomerative clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYFRKFxc5iME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import hierarchical clustering libraries\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Create dendrogram\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))\n",
        "plt.show()\n",
        "\n",
        "# Create clusters and fit\n",
        "hc = AgglomerativeClustering(affinity = 'euclidean', linkage = 'ward')\n",
        "hc.fit(X)\n",
        "\n",
        "# Print number of clusters\n",
        "print(hc.n_clusters_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpqjAske-nHF",
        "colab_type": "text"
      },
      "source": [
        "optimal k\n",
        "1) silhouette_score (-1 ~ 1, 1 -->the best, -1--> the worse)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoFFbQQnCyfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Feature matrix\n",
        "X = diabetes.drop(\"progression\", axis=1)\n",
        "\n",
        "# For loop\n",
        "for n_clusters in range(2,9):\n",
        "    kmeans = KMeans(n_clusters=n_clusters)\n",
        "    preds = kmeans.fit_predict(X)\n",
        "    score = silhouette_score(X, preds, metric='euclidean')\n",
        "    print (\"For n_clusters = {}, silhouette score is {})\".format(n_clusters, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWkIMDMcEBqL",
        "colab_type": "text"
      },
      "source": [
        "2) elbow method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNenQv-UD2dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty list\n",
        "sum_of_squared_distances = []\n",
        "\n",
        "# Create for loop\n",
        "for k in range(1,15):\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    kmeans = kmeans.fit(X)\n",
        "    sum_of_squared_distances.append(kmeans.inertia_)\n",
        "\n",
        "# Plot\n",
        "plt.plot(range(1,15), sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum of squared distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKbi0LG8ED9t",
        "colab_type": "text"
      },
      "source": [
        "### Model Generalization: bootstrapping and cross-validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ0YiwVHGql9",
        "colab_type": "text"
      },
      "source": [
        "GridsearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zUJLHPGqCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=123)\n",
        "\n",
        "# Instantiate, Fit, Predict\n",
        "loans_clf = DecisionTreeClassifier() \n",
        "loans_clf.fit(X_train, y_train)\n",
        "y_pred = loans_clf.predict(X_test)\n",
        "\n",
        "# Evaluation metric\n",
        "print(\"Decision Tree Accuracy: {}\".format(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOZxVjWjEL6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the hyperparameter grid\n",
        "param_grid = {\"criterion\": [\"gini\"], \"min_samples_split\": [2, 10, 20], \n",
        "              \"max_depth\": [None, 2, 5, 10]}\n",
        "\n",
        "# Instantiate classifier and GridSearchCV, fit\n",
        "loans_clf = DecisionTreeClassifier()\n",
        "dtree_cv = GridSearchCV(loans_clf, param_grid, cv=5)\n",
        "fit = dtree_cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the optimal parameters and best score\n",
        "print(\"Tuned Decision Tree Parameter: {}\".format(dtree_cv.best_params_))\n",
        "print(\"Tuned Decision Tree Accuracy: {}\".format(dtree_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-QEA3P-IXNa",
        "colab_type": "text"
      },
      "source": [
        "Random Forest (bootstrap)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3YsPoVCIdS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=123)\n",
        "\n",
        "# Instantiate, Fit, Predict\n",
        "loans_rf = RandomForestClassifier() \n",
        "loans_rf.fit(X_train, y_train)\n",
        "y_pred = loans_rf.predict(X_test)\n",
        "\n",
        "# Evaluation metric\n",
        "print(\"Random Forest Accuracy: {}\".format(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw3NSt9wIy8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import modules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the hyperparameter grid\n",
        "param_grid = {\"criterion\": [\"gini\"], \"min_samples_split\": [2, 10, 20], \n",
        "              \"max_depth\": [None, 2, 5, 10],\"max_features\": [10, 20, 30]}\n",
        "\n",
        "# Instantiate classifier and GridSearchCV, fit\n",
        "loans_rf = RandomForestClassifier()\n",
        "rf_cv = GridSearchCV(loans_rf, param_grid, cv=5)\n",
        "fit = rf_cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the optimal parameters and best score\n",
        "print(\"Tuned Random Forest Parameter: {}\".format(rf_cv.best_params_))\n",
        "print(\"Tuned Random Forest Accuracy: {}\".format(rf_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dQ2WTYkI8Wd",
        "colab_type": "text"
      },
      "source": [
        "### Model evaluation: imbalanced classification models\n",
        "\n",
        "Imbalanced class metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_tZXZuNI9JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Instantiate, fit, predict\n",
        "lr = LogisticRegression(solver='liblinear')\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
        "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(\"Precision: {}\".format(precision_score(y_test, y_pred)))\n",
        "print(\"Recall: {}\".format(recall_score(y_test, y_pred)))\n",
        "print(\"F1: {}\".format(f1_score(y_test, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJxj_85gRL1z",
        "colab_type": "text"
      },
      "source": [
        "Resampling techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9O7ziwfQ_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Resample the minority class, concatenate it with the majority class.\n",
        "# Upsample minority, combine with majority\n",
        "loans_upsampled = resample(deny, replace=True, n_samples=len(approve), random_state=123)\n",
        "upsampled = pd.concat([approve, loans_upsampled])\n",
        "\n",
        "# Instantiate logistic regression, fit, predict\n",
        "loan_lr_up = LogisticRegression(solver='liblinear')\n",
        "loan_lr_up.fit(X_train_up, y_train_up)\n",
        "upsampled_y_pred = loan_lr_up.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, upsampled_y_pred)))\n",
        "print(\"Accuracy: {}\".format(accuracy_score(y_test, upsampled_y_pred)))\n",
        "print(\"Precision: {}\".format(precision_score(y_test, upsampled_y_pred)))\n",
        "print(\"Recall: {}\".format(recall_score(y_test, upsampled_y_pred)))\n",
        "print(\"F1: {}\".format(f1_score(y_test, upsampled_y_pred)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb4HUEXHjXWj",
        "colab_type": "text"
      },
      "source": [
        "Model selection: regression models\n",
        "\n",
        "**multicollinearity**\n",
        "\n",
        "Techniques to address multicollinearity\n",
        "- Correlation matrix\n",
        "- Heatmap of correlations\n",
        "- Calculate the variance ination factor (VIF)\n",
        "- Introduce penalizations (Ridge, Lasso)\n",
        "- PCA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXEssq7-h9xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate, fit, predict\n",
        "lin_mod = LinearRegression()\n",
        "lin_mod.fit(X_train, y_train)\n",
        "y_pred = lin_mod.predict(X_test)\n",
        "\n",
        "# Coefficient estimates\n",
        "print('Coefficients: \\n', lin_mod.coef_)\n",
        "\n",
        "# Mean squared error\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Explained variance score\n",
        "print('R_squared score: %.2f' % r2_score(y_test, y_pred))\n",
        "\n",
        "# Correlation matrix\n",
        "diab_corr = diabetes.corr()\n",
        "\n",
        "# Generate correlation heatmap\n",
        "ax = sns.heatmap(diab_corr, center=0, cmap=sns.diverging_palette(20,220, n=256), square=True)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "plt.show()\n",
        "\n",
        "# Print correlations\n",
        "print(diab_corr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vg6Eqz-se5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature engineering\n",
        "diabetes['s1_s2'] = diabetes['s1'] * diabetes['s2']\n",
        "diabetes = diabetes.drop(['s1','s2'], axis=1)\n",
        "\n",
        "# Print variable names\n",
        "print(diabetes.columns)\n",
        "\n",
        "# Train/test split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=123)\n",
        "# Instantiate, fit, predict\n",
        "lin_mod2 = LinearRegression()\n",
        "lin_mod2.fit(X_train2, y_train2)\n",
        "y_pred2 = lin_mod2.predict(X_test2)\n",
        "\n",
        "# Coefficient estimates\n",
        "print('Coefficients: \\n', lin_mod2.coef_)\n",
        "\n",
        "# Mean squared error\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(y_test2, y_pred2))\n",
        "\n",
        "# Explained variance score\n",
        "print('R_squared score: %.2f' % r2_score(y_test2, y_pred2\n",
        "                                         \n",
        "                                         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe0lqA3CtIOg",
        "colab_type": "text"
      },
      "source": [
        "PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo_DhC50tJJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Instantiate\n",
        "pca = PCA()\n",
        "\n",
        "# Fit on train\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Transform train and test\n",
        "X_trainPCA = pca.transform(X_train)\n",
        "X_testPCA = pca.transform(X_test)\n",
        "\n",
        "# Import\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate, fit, predict\n",
        "LinRegr = LinearRegression()\n",
        "LinRegr.fit(X_trainPCA, y_train)\n",
        "predictions = LinRegr.predict(X_testPCA)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', LinRegr.coef_)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, predictions ))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(y_test, predictions))\n",
        "\n",
        "\n",
        "# Correlation matrix\n",
        "X_trainPCA = pd.DataFrame(X_trainPCA)\n",
        "diab_corrPCA = X_trainPCA.corr()\n",
        "\n",
        "# Generate correlation heatmap\n",
        "ax = sns.heatmap(diab_corrPCA, center=0, cmap=sns.diverging_palette(20,220, n=256), square=True)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "plt.show()\n",
        "\n",
        "# Print correlations\n",
        "print(diab_corrPCA)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQJOevHZuJUn",
        "colab_type": "text"
      },
      "source": [
        "Model selection: ensemble models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-I-fNjduKj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random forest\n",
        "\n",
        "# Import\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Instantiate, fit, predict\n",
        "rf_model = RandomForestClassifier(n_estimators=50, random_state=123, oob_score = True)\n",
        "rf_fit = rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Random Forest Accuracy: {}\".format(accuracy_score(y_test, rf_pred)))\n",
        "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, rf_pred)))\n",
        "print(\"Precision: {}\".format(precision_score(y_test, rf_pred)))\n",
        "print(\"Recall: {}\".format(recall_score(y_test, rf_pred)))\n",
        "print(\"F1: {}\".format(f1_score(y_test, rf_pred)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I3KGLHOxQfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gradient Boosting\n",
        "# Import\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Instantiate, fit, predict\n",
        "gb_model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.01,random_state=123)\n",
        "gb_fit = gb_model.fit(X_train, y_train)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Gradient Boosting Accuracy: {}\".format(accuracy_score(y_test, gb_pred )))\n",
        "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, gb_pred )))\n",
        "print(\"Precision: {}\".format(precision_score(y_test, gb_pred )))\n",
        "print(\"Recall: {}\".format(recall_score(y_test, gb_pred )))\n",
        "print(\"F1: {}\".format(f1_score(y_test, gb_pred )))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}